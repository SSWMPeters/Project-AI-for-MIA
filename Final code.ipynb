{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c99a15a366d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\models\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.losses import mse\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Conv2D, Flatten, Reshape, Conv2DTranspose\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name is CVEA_Project_AI_version_1, class 0\n",
      "Parameters-->\n",
      " Number of epochs: 15\n",
      " Batch size: 32\n",
      " Validation split: 0.85\n",
      " Latend dim: 100\n"
     ]
    }
   ],
   "source": [
    "# Define the base directory where the dataset is located\n",
    "base_dir = 'C:\\\\Users\\\\20203894\\\\Documents\\\\8p361'\n",
    "\n",
    "# Define the model name\n",
    "model_name = 'CVEA_Project_AI_version_'+'1'\n",
    "\n",
    "# Define the file path for saving the model architecture\n",
    "model_filepath = model_name + '.json'\n",
    "\n",
    "# Define the file path for saving the model weights\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "# Batch size for training\n",
    "batch_size = 32\n",
    "\n",
    "# Image size\n",
    "img_size = 96\n",
    "\n",
    "# The number of epochs for training\n",
    "nr_epochs = 15\n",
    "\n",
    "#The split ratio for validation data\n",
    "split = 0.85\n",
    "\n",
    "# The class type (assuming binary classification)\n",
    "class_type = 0\n",
    "\n",
    "# latent dimensions for the VAE\n",
    "latent_dim = 100\n",
    "\n",
    "# Number of images displayed\n",
    "n = 1000 \n",
    "\n",
    "print('Model name is {}, class {}'.format(model_name, class_type))\n",
    "print('Parameters-->\\n Number of epochs: {}\\n Batch size: {}\\n Validation split: {}\\n Latend dim: {}'.format(nr_epochs, batch_size, split, latent_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pcam_generators(base_dir, train_percentage = 0.1, batch_size_gen=batch_size, class_type=class_type, split=split, img_size=img_size):\n",
    "    \"\"\"\n",
    "    Uses the ImageDataGenerator function from the Keras API to return images in batches,\n",
    "    train_gen for the training data and val_gen for the validation data.\n",
    "\n",
    "    Args:\n",
    "        base_dir (str): Base directory containing the dataset.\n",
    "        train_percentage (float): Percentage of training data to be used\n",
    "        train_batch_size (int): Batch size for training data. Default is 32.\n",
    "        val_batch_size (int): Batch size for validation data. Default is 32.\n",
    "        class_type (int): class type to be used. Default is 0.\n",
    "        img_size (int): Size of the images. Default is 96.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing train_gen and val_gen, both are generators.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    # Dataset parameters\n",
    "    # Paths for training and validation data\n",
    "    TRAIN_PATH = os.path.join(base_dir, 'train+val')\n",
    "    VALID_PATH = os.path.join(base_dir, 'train+val')\n",
    "    \n",
    "    # Rescaling factor used to make the range of pixel values between 0 and 1.\n",
    "    RESCALING_FACTOR = 1./255\n",
    "    \n",
    "    # Instantiate data generator for training data with custom percent\n",
    "    train_datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "    \n",
    "    train_data = datagen.flow_from_directory(TRAIN_PATH,\n",
    "                                            target_size=(img_size, img_size),\n",
    "                                            batch_size=batch_size_gen,\n",
    "                                            subset='training',\n",
    "                                            classes=[str(class_type)],\n",
    "                                            class_mode='input')\n",
    "    \n",
    "    # Calculate the number of samples for training data based on % of dataset used\n",
    "    num_train_samples = int(train_percent * len(train_data))\n",
    "    \n",
    "    # Extract desired aount of % of training data for training\n",
    "    train_data_subset = next(train_data)[:num_train_samples]\n",
    "    \n",
    "    \n",
    "    # Instantiate data generator for validation data\n",
    "    val_datagen = ImageDataGenerator(rescale = RESCALING_FACTOR)\n",
    "    val_data = val_datagen.flow_from_directory(VALID_PATH,\n",
    "                                              target_size =(img_size, img_size),\n",
    "                                              batch_size=batch_size_gen,\n",
    "                                              class_mode=\"input\",\n",
    "                                              classes=[str(class_type)],\n",
    "                                              shuffle = False)\n",
    "    \n",
    "    # Calculate number of samples for validation data based on split\n",
    "    num_val_samples = abs((num_train_samples*(1-split))/split)\n",
    "    \n",
    "    # Extract x% of validation data for validation \n",
    "    val_data_subset = next(val_data)[:num_val_samples]\n",
    "                                               \n",
    "    \n",
    "    # Return the generators\n",
    "    return train_data_subset, val_data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_vae(train_gen, val_gen, weights_filepath, model_name, nr_epochs=1, latent_dim=latent_dim, batch_size=batch_size, img_size=img_size):\n",
    "    \n",
    "    # Define input shape and latent dimension\n",
    "    input_shape = (img_size, img_size, 3)\n",
    "    \n",
    "    # Encoder network\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', strides=(2, 2), padding='same')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    shape_before_flattening = K.int_shape(x)\n",
    "    x = Flatten()(x)\n",
    "    z_mean = Dense(latent_dim)(x)\n",
    "    z_log_var = Dense(latent_dim)(x)\n",
    "    \n",
    "\n",
    "    # Sampling function\n",
    "    @tf.function\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    \n",
    "\n",
    "    # Reparameterization trick\n",
    "    z = Lambda(sampling)([z_mean, z_log_var])\n",
    "    \n",
    "\n",
    "    # Decoder network\n",
    "    decoder_input = Input(K.int_shape(z)[1:])\n",
    "    x = Dense(np.prod(shape_before_flattening[1:]), activation='relu')(decoder_input)\n",
    "    x = Reshape(shape_before_flattening[1:])(x)\n",
    "    x = Conv2DTranspose(128, (2, 2), activation='relu', padding='same', )(x)\n",
    "    x = Conv2DTranspose(64, (2, 2), activation='relu', padding='same', strides=(2, 2))(x)\n",
    "    x = Conv2DTranspose(32, (2, 2), activation='relu', padding='same', )(x)\n",
    "    x = Conv2DTranspose(16, (2, 2), activation='relu', padding='same', )(x)\n",
    "    x = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    # Define the VAE model\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    decoder = Model(decoder_input, x, name='decoder')\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, outputs, name=model_name)\n",
    "\n",
    "    # Define the VAE loss function\n",
    "    reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "    reconstruction_loss *= input_shape[0] * input_shape[1] * input_shape[2]\n",
    "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=1)\n",
    "    B = 1000   \n",
    "    vae_loss = K.mean(B * reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.add_metric(kl_loss, name=\"kl_loss\")\n",
    "    vae.add_metric(reconstruction_loss, name=\"reconstruction_loss\")\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    # Serialize model to JSON\n",
    "    model_json = vae.to_json() # serialize model to JSON\n",
    "    with open(model_name, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "    # Define EarlyStopping callback to stop training when the model stops improving\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 5,\n",
    "                                  restore_best_weights=True)\n",
    "    \n",
    "    # Define other callbacks\n",
    "    checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    tensorboard = TensorBoard(log_dir=os.path.join('logs', model_name))\n",
    "    callbacks_list = [early_stopping, checkpoint, tensorboard]\n",
    "\n",
    "    # Calculate number of steps per epoch for training and validation sets\n",
    "    train_steps = train_gen.n // train_gen.batch_size\n",
    "    val_steps = val_gen.n // val_gen.batch_size\n",
    "    \n",
    "    # Fit the VAE model\n",
    "    vae.fit(train_gen, \n",
    "            steps_per_epoch=train_steps, \n",
    "            epochs=nr_epochs, \n",
    "            batch_size=batch_size, \n",
    "            validation_data=val_gen, \n",
    "            validation_steps=val_steps,\n",
    "            callbacks=callbacks_list)\n",
    "    \n",
    "    # Returns the trained VAE model\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_img(vae, val_gen, img_size=img_size):\n",
    "    \n",
    "    # Reconstruct images using the trained VAE model\n",
    "    decoded_imgs = vae.predict(val_gen)\n",
    "    \n",
    "    \n",
    "    # Display the original and reconstructed images\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        \n",
    "        # Display the original image\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        img, label = val_gen.next()\n",
    "        plt.imshow(img[0])\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # Display the reconstructed image\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(img_size, img_size,3))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def generate_new_img(vae, base_dir, class_type=0, num_samples=10, delete_files=True, img_size=img_size):\n",
    "    \n",
    "    # Generate new images using random latent vectors\n",
    "    random_latent_vectors  = np.random.random((num_samples, img_size, img_size, 3))\n",
    "    decoded_imgs = vae.predict(random_latent_vectors)\n",
    "    \n",
    "    # Path to the directory where you want to save the images\n",
    "    save_dir = base_dir + \"/train_new_iamges/{}/\".format(str(class_type))\n",
    "\n",
    "    # Create the save directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Optionally delete existing files in the directory\n",
    "    for file in os.listdir(save_dir):\n",
    "        if file.endswith('.jpg') and delete_files == True:\n",
    "            os.remove(save_dir + file)\n",
    "\n",
    "    # Iterate through generated images and save them\n",
    "    for i in range(len(decoded_imgs)):\n",
    "        img = decoded_imgs[i].reshape(img_size, img_size,3)\n",
    "        \n",
    "        # Generate a random name for the image\n",
    "        random_name = ''.join(random.choices('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ', k=10))\n",
    "        \n",
    "        # Save the image with the random name and jpg extension\n",
    "        plt.imsave(os.path.join(save_dir, random_name + \".jpg\"), img)\n",
    "\n",
    "    print(\"Images saved to:\", save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform autoencoder for specified classes (for both classes = [0,1])\n",
    "classes = [0,1]\n",
    "for i in classes:\n",
    "    # Get data generators for the specified class\n",
    "    train_gen, val_gen = get_pcam_generators(base_dir, batch_size_gen=batch_size, class_type=i)\n",
    "    \n",
    "    # Construct VAE model and train it\n",
    "    vae = construct_vae(train_gen, val_gen, weights_filepath, model_name, nr_epochs, latent_dim)\n",
    "    \n",
    "    # Reconstruct and display images\n",
    "    reconstruct_img(vae, val_gen)\n",
    "    \n",
    "    # Generate new images and save them\n",
    "    generate_new_img(vae, base_dir, class_type=i, num_samples=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
